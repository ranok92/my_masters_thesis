\chapter*{\rm\bfseries Abstract}
In this work, we present a navigation pipeline using maximum entropy deep inverse reinforcement learning (MEDIRL) that relies on expert demonstrations to learn social compliance.\\
The ability to navigate autonomously is one of the primary milestones of mobile robots. And with the increasing rate of deployment of robots in the proximity of humans, a socially compliant navigation system is a necessity. We define socially compliant navigation as a form of navigation that in addition to satisfying the principles of classical navigation, maintains some form semblance to the way humans move through crowds. Generally, this is an amalgamation of several factors including but not limited to personal preferences, social and cultural norms, and present circumstances, making the problem quite challenging.\\
 The primary contributions of this thesis lie in the adaptation of MEDIRL in a model-free environment and a set of novel yet simple feature representation that captures relevant information from the environment enabling the agent to navigate in a human-like way. \edited{We train our method using a $4$-minute long, publicly available dataset of people walking through a university campus and test its performance against existing bodies of work. We perform two sets of experiments: first to showcase the performance of IRL against other available methods and next to compare our proposed feature representation to others in the literature. When comparing to other methods, we find that trajectories produced by our approach show significant resemblance to human demonstrations while maintaining comparable performance at reaching the goal in a collision-free path. And, when compared with other feature representations, our approach displayed a significantly greater success rate at reaching the goal with \textbf{marginal} improvement at mimicking the expert.}\\
  \textcolor{red}{Based on the results (drift analysis) I am not sure if I can say 'marginal' improvement or 'substantial' improvements. Maybe you can help?}
 
 
% The results show that the trajectories produced by agents trained from our approach have a greater resemblance to human demonstrations when compared to other existing methods maintaining comparable performance in the task of finding a collision-free trajectory to the goal.


